{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff50318a",
   "metadata": {},
   "source": [
    "# Basic Analysis \n",
    "\n",
    "In text analysis, we often create features from our text. A feature is simply a piece of measurabble information. Before we do any cleaning or comeplex analysis, we can get a great overview of our dataset by extracting some simple high-lebel features. This helps us understand the \"shape\" of our text data. \n",
    "\n",
    "#### In this notebook, you will learn how to:\n",
    "- Create new columns \n",
    "- Calculate basic features like character count, word count and punctuation count\n",
    "- Calculate a more advanced feature like average word length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cd0791",
   "metadata": {},
   "source": [
    "## Setup: Loading the BBC dataset\n",
    "This cell will import pandas and load the BBC News dataset from the stable URL. The DataFrame will be called bbc_df, and the main column we'll be working with is 'text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b394c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "Shape of the DataFrame: (2225, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# This URL points to a stable dataset hosted on Google Cloud Storage.\n",
    "url = 'https://storage.googleapis.com/dataset-uploader/bbc/bbc-text.csv'\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "bbc_df = pd.read_csv(url)\n",
    "\n",
    "print(\"BBC News dataset loaded successfully!\")\n",
    "print(\"Shape of the DataFrame:\", bbc_df.shape)\n",
    "bbc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a46217",
   "metadata": {},
   "source": [
    "### Basic Count Features \n",
    "\n",
    "Let's start creating three columns in our DataFrame to store some basic counts for each review. \n",
    "\n",
    "#### Character Count\n",
    "This is the total number of characters in the review, including letters, spaces and punctuation. It gives us a rough idea of the review's length. We can get this easily using .str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785b7818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'char_count'\n",
    "bbc_df['char_count'] = bbc_df['text'].str.len()\n",
    "\n",
    "# Look at the first few rows with our new column\n",
    "bbc_df[['text', 'char_count']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef932129",
   "metadata": {},
   "source": [
    "#### Worod Count\n",
    "How many words are in each review? To get this, we can use a two-step process:\n",
    "1. Use .str.split() to split each review string into a list of words\n",
    "2. Use .apply(len) to run the len() function on each list to count the number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d863fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'word_count'\n",
    "bbc_df['word_count'] = bbc_df['text'].str.split().apply(len)\n",
    "\n",
    "# Look at the first few rows with our new column\n",
    "bbc_df[['text', 'word_count']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4c490d",
   "metadata": {},
   "source": [
    "#### Punctuation Count\n",
    "Let's see how \"noisy\" our text is by counting the number of punctuation marks. This will be very useful later to see if our cleaning process works. We'll use str.count() with a regular expression that looks for common punctuation. _You don't need to understand what a regular expression is, just think of it as template that we can use to find certain charaters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a23dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'punc_count'\n",
    "# The [.,!?:;-] part is a simple regular expression that counts any of those characters.\n",
    "bbc_df['punc_count'] = bbc_df['text'].str.count(r'[.,!?:;-]')\n",
    "\n",
    "# Look at the first few rows with our new column\n",
    "bbc_df[['text', 'punc_count']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b06f7a",
   "metadata": {},
   "source": [
    "### A more revealing Feature: Average Word Length\n",
    "Since we can have longer reviews, we can calculate more interesting features. The Averaged word length can sometimes give us clues abou the complexity of style of the text.\n",
    "\n",
    "To calculate this, we can't just divide the character count by the word cocunt, because the character count includes spaces!\n",
    "\n",
    "Here is the correct way to do it:\n",
    "1. Remove all the spaces from the text \n",
    "2. Count the characters in the text without spaces\n",
    "3. Divide that by the total word count \n",
    "\n",
    "Let's write a small functionn to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505a5b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function calculates the average word length for a given text\n",
    "def calculate_avg_word_length(text):\n",
    "    words = text.split()\n",
    "    total_chars = len(\"\".join(words))\n",
    "    total_words = len(words)\n",
    "    # Avoid dividing by zero for any empty text\n",
    "    if total_words == 0:\n",
    "        return 0\n",
    "    return total_chars / total_words\n",
    "\n",
    "# Create a new column 'avg_word_length' by applying our function to the 'text' column\n",
    "bbc_df['avg_word_length'] = bbc_df['text'].apply(calculate_avg_word_length)\n",
    "\n",
    "# Look at the first few rows with all our new feature columns\n",
    "bbc_df[['text', 'char_count', 'word_count', 'avg_word_length']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ede8069",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Time to practice. Use the imdb_df dataframe with its new columns to answer three questions\n",
    "\n",
    "#### Exercise 1: The Longest Article\n",
    "Find the word count of the longest article in the entire dataset. (Hint: use the .max() method on the 'word_count' column).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8de475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Exercise 1 here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b212714",
   "metadata": {},
   "source": [
    "#### Exercise 2: Overall Average Word Count\n",
    "What is the average word_count for an article across the whole dataset? (Hint: use the .mean() method on the 'word_count' column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bf342f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Exercise 2 here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fbba88",
   "metadata": {},
   "source": [
    "#### Exercise 3: Averages by Category (Advanced)\n",
    "This dataset has a 'category' column. Can you calculate the average word count for each category? This is a very common task in data analysis.\n",
    "\n",
    "(Hint: The easiest way to do this is with Pandas' .groupby() method: bbc_df.groupby('category')['word_count'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d3db67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for Exercise 3 here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0627f2e",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "You have learned to take a raw text dataset and immediately start creating meaningful features. You can see how even simple counts can give a better understanding of your data. You have probabbly also noticed how capitalisation and punctuation will affect our count. Im this next notebook, we will address this directly by cleaning and pre-processing our text to make it standardised and ready for more advanced analysis. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
