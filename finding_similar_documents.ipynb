{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f30d643",
   "metadata": {},
   "source": [
    "# Finding Similar Documents \n",
    "Objective: To learn how to mathematically  calculate how similar two documents are. This is the core concept behind reccomendation engines and semantic search\n",
    "\n",
    "## The concept: From Text to Vectors\n",
    "How can we know if two articles are similar? The core idea is this: _if we represent each document as a numerical vector, we can then use mathematical formulas to measure the \"distance\" or \"angle\" between these vectors_. Documents with similar vector representations are likely about similar topics\n",
    "\n",
    "### Setup and Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a907190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Note: We'll re-use a simplified cleaning process here\n",
    "import re\n",
    "\n",
    "def simple_clean(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# Load and clean the data\n",
    "url = 'https://storage.googleapis.com/dataset-uploader/bbc/bbc-text.csv'\n",
    "bbc_df = pd.read_csv(url)\n",
    "bbc_df['cleaned_text'] = bbc_df['text'].apply(simple_clean)\n",
    "\n",
    "# Vectorize the text with TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(bbc_df['cleaned_text'])\n",
    "\n",
    "print(\"Setup complete. Text has been vectorized.\")\n",
    "print(\"Shape of our TF-IDF Matrix:\", tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d868756d",
   "metadata": {},
   "source": [
    "### Measuring Similarity: Cosine Similartity\n",
    "The most common way to measure the similarity between two text vectors is Cosine Similarity.\n",
    "\n",
    "It measures the cosine of the angle between two vectors.\n",
    "- A score of 1 means the vectors are identical (angle is 0°).\n",
    "- A score of 0 means the vectors are completely unrelated (angle is 90°).\n",
    "\n",
    "scikit-learn has a function that makes this very easy to calculate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac83f77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cosine similarity between the first document and ALL documents\n",
    "# The result is a matrix where each value is the similarity score\n",
    "cosine_sim_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "print(\"Shape of the similarity matrix:\", cosine_sim_matrix.shape)\n",
    "\n",
    "# Let's look at the similarity of the first 5 docs to each other\n",
    "print(\"\\nSimilarity matrix for the first 5 documents:\")\n",
    "print(cosine_sim_matrix[0:5, 0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10798ce3",
   "metadata": {},
   "source": [
    "### Building a Simple Recommendation Function\n",
    "Let's put this together into a function that, given one article finds the n most similar articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e66c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_articles(article_index, top_n=5):\n",
    "    # Get the similarity scores for the given article\n",
    "    similar_scores = list(enumerate(cosine_sim_matrix[article_index]))\n",
    "    \n",
    "    # Sort the articles based on similarity score in descending order\n",
    "    sorted_similar_scores = sorted(similar_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the indices of the top N most similar articles (excluding the article itself)\n",
    "    top_indices = [i[0] for i in sorted_similar_scores[1:top_n+1]]\n",
    "    \n",
    "    print(f\"--- Top {top_n} articles similar to Article {article_index} ---\")\n",
    "    print(f\"ORIGINAL: {bbc_df['text'].iloc[article_index][:100]}...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Return the most similar articles\n",
    "    return bbc_df.iloc[top_indices]\n",
    "\n",
    "# Let's test it! Find articles similar to the first one in the dataset.\n",
    "find_similar_articles(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1649344",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "You task is to use the find_similar_articles function to find the top 3 most similar articles to Article 500\n",
    "- Call the function with theh correct parameters(artcile_index=500, top_n=3)\n",
    "- Look at the category of the original article and the categories of the recommended articles  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388e7e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for the Exercise here\n",
    "# First, see what the original article is about\n",
    "print(\"--- Original Article #500 ---\")\n",
    "print(bbc_df.iloc[500])\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Now, find similar articles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
